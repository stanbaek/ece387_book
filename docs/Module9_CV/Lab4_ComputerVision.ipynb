{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f974aa57",
   "metadata": {},
   "source": [
    "# Lab 4: Computer Vision\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bd3e2",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This lab will integrate a USB Camera with the Robot. You will use a Python script to take pictures of the stop sign and build a stop sign detector then test it using a live video feed. You will then use the detector and known size of the stop sign to estimate how far the stop sign is from the camera. Lastly, you will create a node to identify and determine how far an April Tag is from the robot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d10b9",
   "metadata": {},
   "source": [
    "## Setup packages\n",
    "Open a terminal on the **Master** and create a lab4 package:\n",
    "\n",
    "```bash\n",
    "cd ~/master_ws/src/ece387_master_spring202X-USERNAME/\n",
    "catkin_create_pkg lab4 rospy sensor_msgs std_msgs cv_bridge apriltag_ros\n",
    "```\n",
    "\n",
    "Make and source your workspace.\n",
    "\n",
    "If you have not already done so, repeat on the **Robot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb34a7b",
   "metadata": {},
   "source": [
    "## Create a ROS node to save images\n",
    "Browse to your lab4 source folder on the **Master** and create a node called **image_capture.py**.\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "import rospy, cv2, argparse\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "class SavingImage(object):\n",
    "\tdef __init__(self, img_dest):\n",
    "\t\tself.img_dest = img_dest\n",
    "\t\tself.ctrl_c = False\n",
    "\t\tself.count = 0\n",
    "        \n",
    "        # subscribe to the topic created by the usb_cam node\n",
    "\t\tself.image_sub = rospy.Subscriber(\"/usb_cam/image_raw\",Image,self.camera_callback)\n",
    "        \n",
    "        # CV bridge converts between ROS Image messages and OpenCV images\n",
    "\t\tself.bridge_object = CvBridge()\n",
    "        \n",
    "        # callback to save images when user presses button\n",
    "\t\trospy.Timer(rospy.Duration(.1), self.callback_save)\n",
    "\t\t\n",
    "\t\trospy.on_shutdown(self.shutdownhook)\n",
    "\n",
    "\tdef camera_callback(self,img):\n",
    "\t\tif not self.ctrl_c:\n",
    "\t\t\ttry:\n",
    "                # convert ROS image to OpenCV image\n",
    "\t\t\t\tself.cv_image = self.bridge_object.imgmsg_to_cv2(img, desired_encoding=\"bgr8\")\n",
    "\t\t\texcept CvBridgeError as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\n",
    "            # show the image (waitKey(1) allows for automatic refressh creating video)\n",
    "\t\t\tcv2.imshow('image', self.cv_image)\n",
    "\t\t\tcv2.waitKey(1)\n",
    "\t\t\n",
    "\tdef callback_save(self, event):\n",
    "        # when user is ready to take picture press button\n",
    "\t\t_ = input(\"Press enter to save the next image.\")\n",
    "\t\tdest = self.img_dest + \"img\" + str(self.count) + \".jpg\"\n",
    "\t\tself.count += 1\n",
    "\t\tprint(dest)\n",
    "\t\ttry:\n",
    "            # write to file\n",
    "\t\t\tcv2.imwrite(dest, self.cv_image)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Not valid image name. Try restarting with valid path.\")\n",
    "\t\t\t\n",
    "\tdef shutdownhook(self):\n",
    "\t\tprint(\"Shutting down\")\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\trospy.init_node('image_saver', anonymous=True)\n",
    "\tap = argparse.ArgumentParser()\n",
    "\tap.add_argument(\"-o\", \"--output\", required=True, help=\"path to output img\")\n",
    "\targs = vars(ap.parse_args())\n",
    "\tsaving_image_object = SavingImage(args[\"output\"])\n",
    "\ttry:\n",
    "\t\trospy.spin()\n",
    "\texcept KeyboardInterrupt:\n",
    "\t\tpass\n",
    "```\n",
    "\n",
    "Save, exit, and make executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0a829",
   "metadata": {},
   "source": [
    "## Train your stop detector\n",
    "\n",
    "Create a new folder in your **lab4** package called **training_images**.\n",
    "\n",
    "Run the `image_capture.py` node on the **Master** using the following command:\n",
    "\n",
    "```bash\n",
    "rosrun lab4 image_capture.py -o /home/dfec/master_ws/src/ece387_master_spring202X-NAME/lab4/training_images/\n",
    "```\n",
    "\n",
    "Store images of the stop sign by pressing `enter` when prompted. You decide how many and at what orientations to properly train your detector. When complete, hit `ctrl+c` to exit.\n",
    "\n",
    "Utilize the steps from Module 9: [Building a detector using HOG features](ICE9_ComputerVision.ipynb#Building-a-detector-using-HOG-features) to label your images and train your object detector using the new images, saving the `stop_detector.svm` file within the **training_images** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23251d",
   "metadata": {},
   "source": [
    "## Test your stop detector\n",
    "Create a node in the **lab4** package on the **Master** called `stop_detector.py` and copy the below into it:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "import rospy, cv2, dlib\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "# TODO: import usb_cam message type\n",
    "\n",
    "\n",
    "class StopDetector(object):\n",
    "\n",
    "    def __init__(self, detectorLoc):\n",
    "        self.ctrl_c = False\n",
    "        \n",
    "        #TODO: create subscriber to usb_cam image topic\n",
    "\n",
    "        \n",
    "        self.bridge_object = CvBridge()\n",
    "        self.detector = dlib.simple_object_detector(detectorLoc)\n",
    "        \n",
    "        rospy.on_shutdown(self.shutdownhook)\n",
    "        \n",
    "    def camera_callback(self,data):\n",
    "        if not self.ctrl_c:\n",
    "            #TODO: write code to get ROS image, convert to OpenCV image,\n",
    "            # apply detector, add boxes to image, and display image\n",
    "            \n",
    "\n",
    "    def shutdownhook(self):\n",
    "        print(\"Shutting down\")\n",
    "        self.ctrl_c = True\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    rospy.init_node('stop_detector')\n",
    "    detector = rospy.get_param(\"/stop_detector/detector\")\n",
    "    stop_detector = StopDetector(detector)\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "```\n",
    "\n",
    "Edit the `stop_detector.py` node so it utilizes the `camera_callback()` function we used above to get images from the camera.\n",
    "\n",
    "After getting the `cv_image` within the `camera_callback()`, apply the detector in a similar method as Module 9: [Testing a detector](ICE9_ComputerVision.ipynb#Testing-a-detector) creating boxes around all detected stop signs. Using a `waitKey(1)` will allow for the image to refresh automatically without user input and display the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534b466",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "Demonstrate the stop detector on the **Master** detecting a stop sign from the **Robot's** camera.\n",
    "\n",
    "```bash\n",
    "rosrun lab4 stop_detector.py _detector:=/home/dfec/master_ws/src/ece387_master_spring202X-NAME/lab4/training_images/stop_detector.svm\n",
    "```\n",
    "\n",
    ">üìùÔ∏è **Note:** You must have the `lab4.launch` file running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112111cb",
   "metadata": {},
   "source": [
    "## Move detector to robot\n",
    "Copy the detector and node to the robot:\n",
    "\n",
    "```bash\n",
    "roscd lab4/training_images\n",
    "scp stop_detector.svm pi@robotX:/home/pi/robot_ws/src/ece387_robot_spring202X-NAME/lab4/training_images/stop_detector.svm\n",
    "roscd lab4/src\n",
    "scp stop_detector.py pi@robotX:/home/pi/robot_ws/src/ece387_robot_spring202X-NAME/lab4/src/stop_detector.py\n",
    "```\n",
    "\n",
    "Remove the lines that display the video and instead print \"Stop detected\" if `boxes` is not empty.\n",
    "\n",
    "Do you note a difference in processing speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25d561",
   "metadata": {},
   "source": [
    "## Launch file\n",
    "Edit the `lab4.launch` file so it will run the stop detector node with the `detector` param set to the location of the detector. For example:\n",
    "\n",
    "```xml\n",
    "<node machine=\"robotX\" name=\"stop_detector\" pkg=\"lab4\" type=\"stop_detector.py\" output=\"screen\">\n",
    "    <param name=\"detector\" value=\"/home/pi/robot_ws/src/ece387_robot_spring202X-Name/robot/lab4/training_images/sl_detector.svm\"/>\n",
    "</node>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41211803",
   "metadata": {},
   "source": [
    "## Checkpoint 2\n",
    "Demonstrate the stop detector on the **Robot** detecting a stop sign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc41f5",
   "metadata": {},
   "source": [
    "## Determine distance from stop sign\n",
    "\n",
    "### Edit `stop_detector.py`\n",
    "\n",
    "You will edit your stop sign detector on the **Robot** to calculate an estimated distance between the camera and the stop sign using triangle similarity. \n",
    "\n",
    "Given a stop sign with a known width, $W$, we can place the stop sign at a known distance, $D$, from our camera. The detector will then detect the stop sign and provide a perceived width in pixels, $P$. Using these values we can calculate the focal length, $F$ of our camera:\n",
    "\n",
    "$F = \\frac{(P\\times D)}{W}$\n",
    "\n",
    "We can then use the calculated focal length, $F$, known width, $W$, and perceived width in pixels, $P$ to calculate the distance from the camera:\n",
    "\n",
    "$D' = \\frac{(W\\times F)}{P}$\n",
    "\n",
    "Use the above information and create two class variables, `FOCAL` and `STOP_WIDTH`, and a class function to calculate distance given a known `FOCAL` length and a known width of the stop sign, `STOP_WIDTH`. You will need to print the perceived width of the stop sign to determine the $P$ value used in the calculation to find the focal length.\n",
    "\n",
    "> üí°Ô∏è **Tip:** Pay attention to what the `x` and `w` variables of the `box` actually represent!\n",
    "\n",
    "Create a new publisher that will publish the distance using **Float32** *std_msgs* messages over the */stop_dist* topic.\n",
    "\n",
    "Publish the distance of each object seen in the image. \n",
    "\n",
    "Remove any print statements after troubleshooting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f2523",
   "metadata": {},
   "source": [
    "## Checkpoint 3\n",
    "Demonstrate the **stop_detector** node publishing distance from the stop sign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f84309",
   "metadata": {},
   "source": [
    "## Printing April Tag information\n",
    "\n",
    "Create a node on the master in lab4 called `apriltag_dist.py`. Import the appropriate AprilTag message. Subscribe to the `tag_detections` topic. Print the identified AprilTag ID and distance. If the camera sees multiple tags, it should print the information for each tag.\n",
    "\n",
    "In your callback function you will want to create a for loop such as:\n",
    "\n",
    "```python\n",
    "for tag in data.detections:\n",
    "```\n",
    "\n",
    "Use print statements to determine the characteristics of the message (you can also google the message).\n",
    "\n",
    "Add the `apriltag_dist` node to the **lab4** launch file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546cf86",
   "metadata": {},
   "source": [
    "## Checkpoint 4\n",
    "\n",
    "Demonstrate the `apriltag_dist` node printing the ID and distance of each April Tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356d621",
   "metadata": {},
   "source": [
    "## Report\n",
    "Complete a short 2-3 page report that utilizes the format and answers the questions within the report template. The report template and an example report can be found within the Team under `Resources/Lab Template`.\n",
    "\n",
    "> üìùÔ∏è **Note:** We will be primarily grading sections 3.1, 3.2, and 3.3 for this lab, but do include the entire lab as you will need other components for the final project report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96fea1",
   "metadata": {},
   "source": [
    "## Turn-in Requirements\n",
    "**[25 points]** All checkpoints marked off.\n",
    "\n",
    "**[50 points]** Report via Gradescope.\n",
    "\n",
    "**[25 points]** Code: push your code to your repository. Also, include a screen shot of the **apriltag_dist.py** and **stop_detector.py** files at the end of your report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "339px",
    "width": "355px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
